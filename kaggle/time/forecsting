import numpy as no
import time 
import PIL.Image as Image
import matplotlib.pylab as plt
import matplotlib.image as mpimg
%matplotlib inline
import datetime
from tqdm.keras import TqdmCallback
from skimage import transform
import urllib
import os

import tensorflow as tf
import tensorflow_hub as hub

pip install tensorflow_hub

daytime_validation_dir="/Users/mrmmm/OneDrive/time/validation/daytime"
nighttime_validation_dir="/Users/mrmmm/OneDrive/time/validation/nighttime"
sunrise_validation_dir="/Users/mrmmm/OneDrive/time/validation/sunrise"
daytime_test_dir="/Users/mrmmm/OneDrive/time/test/daytime"
nighttime_test_dir="/Users/mrmmm/OneDrive/time/test/nighttime"
sunrise_test_dir="/Users/mrmmm/OneDrive/time/test/sunrise"
daytime_train_dir="/Users/mrmmm/OneDrive/time/train/daytime"
nighttime_train_dir="/Users/mrmmm/OneDrive/time/train/nighttime"
sunrise_train_dir="/Users/mrmmm/OneDrive/time/train/sunrise"
original_daytime_dir="/Users/mrmmm/OneDrive/time/original/daytime"
original_nighttime_dir="/Users/mrmmm/OneDrive/time/original/nighttime"
original_sunrise_dir="/Users/mrmmm/OneDrive/time/original/sunrise"
test_dir="/Users/mrmmm/OneDrive/time/test"
validation_dir="/Users/mrmmm/OneDrive/time/validation"
train_dir="/Users/mrmmm/OneDrive/time/train2"

batch_size=64
img_height=224
img_width=224
seed_train_validation=1
shuffle_value=True
validation_split=0.1

train_ds=tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split=validation_split,
    subset="training",
    image_size=(img_height,img_width),
    batch_size=batch_size,
    seed=seed_train_validation,
    shuffle=shuffle_value)

val_ds=tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    validation_split=validation_split,
    subset="validation",
    image_size=(img_height,img_width),
    batch_size=batch_size,
    seed=seed_train_validation,
    shuffle=shuffle_value)
    
class_name=train_ds.class_names
print("the target classes are:",class_name,sep=",")

normalization_layer=tf.keras.layers.Rescaling(1./255)
train_ds=train_ds.map(lambda x,y:(normalization_layer(x),y))
val_ds=val_ds.map(lambda x,y:(normalization_layer(x),y))
AUTOTUNE=tf.data.AUTOTUNE
train_ds=train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)

efficientnet_v2_fv='https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/feature_vector/2'
feature_extractor_model=efficientnet_v2_fv

feature_extractor_layer=hub.KerasLayer(
    feature_extractor_model,
    input_shape=(img_width,img_height,3),
    trainable=False)

num_classes=len(class_name)

model=tf.keras.Sequential([
    feature_extractor_layer,
    tf.keras.layers.Dense(num_classes)
])

model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=["acc"]
)

early_stopping=tf.keras.callbacks.EarlyStopping(monitor="loss",patience=3)
NUM_EPOCHS=20

history=model.fit(train_ds,validation_data=val_ds,epochs=NUM_EPOCHS,callbacks=[early_stopping,TqdmCallback(verbose=0)],verbose=0)

model_acc="{:.2%}".format(history.history["acc"][-1])
print(f"\nModel Accuracy Reached:{model_acc}")

import matplotlib.pyplot as plt
epochs=range(0,NUM_EPOCHS)
acc=history.history["acc"]
val_acc=history.history["val_acc"]
plt.plot(epochs,acc,"b",label="training")
plt.plot(epochs,val_acc,"bo",label="validation")
plt.legend()
plt.show()

