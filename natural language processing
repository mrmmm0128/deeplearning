pip install tensorflow
from keras.layers import Embedding
from keras.preprocessing.text import Tokenizer
tokenizer=Tokenizer(num_words=1000)
word_index=tokenizer.word_index
embedding_layer=Embedding(1000,64)
import keras
from keras.datasets import imdb
from keras import preprocessing
from keras import utils

max_features=10000
max_len=20

(data1,label1),(data2,label2)=imdb.load_data(num_words=max_features)

import numpy as np
max_len=100
training_sample=200
validation_sample=10000
max_words=10000
data=np.concatenate([data1,data2])
label=np.concatenate([label1,label2])
data=utils.pad_sequences(data,maxlen=max_len)

indices=np.arange(data.shape[0])
np.random.shuffle(indices)
data=data[indices]
labels=label[indices]

x_train=data[:training_sample]
x_test=data[training_sample:training_sample+validation_sample]
y_train=labels[:training_sample]
y_test=labels[training_sample:training_sample+validation_sample]

glove_dir="/Users/mrmmm/Downloads/glove.6B"

embeddings_index={}
f=open(os.path.join(glove_dir,"glove.6B.100d.txt"),encoding="utf-8")
for line in f:
    values=line.split()
    word=values[0]
    coefs=np.asarray(values[1:],dtype="float32")
    embeddings_index[word]=coefs
f.close()

print("Found %ss word vectors."% len(embeddings_index))

embedding_dim=100

embedding_matrix=np.zeros((max_words,embedding_dim))
for word,i in word_index.items():
    if embedding_vector is not None:
        embedding_matrix[i]=embedding_vector
        
from keras.models import Sequential
from keras.layers import Embedding,Flatten,Dense

model=Sequential()
model.add(Embedding(max_words,embedding_dim,input_length=max_len))
model.add(Flatten())
model.add(Dense(32,activation="relu"))
model.add(Dense(1,activation="sigmoid"))
model.summary()

model.layers[0].set_weights([embedding_matrix])
model.layers[0].trainable=False

model.compile(optimizer="rmsprop",loss="binary_crossentropy",metrics=["acc"])

history=model.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_test,y_test))

import matplotlib.pyplot as plt
acc=history.history["acc"]
val_acc=history.history["val_acc"]
loss=history.history["loss"]
val_loss=history.history["val_loss"]

epochs=range(1,len(acc)+1)

plt.plot(epochs,acc,"bo",label="training acc")
plt.plot(epochs,val_acc,"b",label="validation acc")
plt.title("training and validation acc")
plt.legend()

plt.figure()

plt.plot(epochs,loss,"bo",label="training loss")
plt.plot(epochs,val_loss,"b",label="validation loss")
plt.title("training and validation loss")
plt.legend()

plt.show()
